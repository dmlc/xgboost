# General Parameters, see comment for each definition
# choose the booster, can be gbtree or gblinear
booster = gbtree
# choose logistic regression loss function for binary classification
objective = binary:logistic

# Tree Booster Parameters
# step size shrinkage
eta = 0.05
# minimum loss reduction required to make a further partition
#gamma = 1.0
# minimum sum of instance weight(hessian) needed in a child
min_child_weight = 20
# maximum depth of a tree
max_depth = 2
early_stopping_round = 5

# Task Parameters
# the number of round to do boosting
num_round = 500
# 0 means do not save any model except the final round model
#save_period = 0
#
# The path of training data
data = "data/train_data.txt" 

# The path of validation data, used to monitor training process, here [test] sets name of the validation set
eval_metric = auc
eval_metric = rmse

eval[test] = "data/test_data.txt"

model_out = "result/gbdt.model"

